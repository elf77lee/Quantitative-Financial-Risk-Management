{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00000-163e941c-f776-4366-a86a-dbcc3e9de7f1",
    "deepnote_cell_type": "code"
   },
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom datetime import date\nfrom sklearn.preprocessing import OneHotEncoder\nimport re\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\nimport pickle\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn import preprocessing",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00001-5c453ab7-2336-4b4f-b3bf-d8705408eb53",
    "deepnote_cell_type": "code"
   },
   "source": "def calculate_age(birthDate):\n    #birthDate=str(birthDate)\n    d,m,y = birthDate.split('-')\n    if int(y) < 21: y='20'+y\n    else: y= '19'+y\n    b = date(int(y),int(m),int(d))\n    today=date.today()\n    return today.year - b.year - ((today.month, today.day) <(b.month, b.day))\n\ndef yrs_mon_to_month(s):\n    sp=re.split('yrs|mon',s)\n    return int(sp[0])*12 + int(sp[1])\n\ndef encode_description(X):\n    '''\n\n    '''\n    X=X.drop('PERFORM_CNS.SCORE', axis=1) # drop PERFORM_CNS.SCORE\n    X['PERFORM_CNS.SCORE.DESCRIPTION'] = X['PERFORM_CNS.SCORE.DESCRIPTION'].replace(('No Bureau History Available', \n                                     'Not Scored: Sufficient History Not Available','Not Scored: Not Enough Info available on the customer',\n                                     'Not Scored: No Activity seen on the customer (Inactive)', \n                                     'Not Scored: No Updates available in last 36 months', 'Not Scored: Only a Guarantor'),(0, 0, 0, 0, 0, 0))\n\n    X['PERFORM_CNS.SCORE.DESCRIPTION'] = X['PERFORM_CNS.SCORE.DESCRIPTION'].replace(('L-Very High Risk', 'M-Very High Risk', \n                                     'Not Scored: More than 50 active Accounts found'), (1, 1, 1))\n\n    X['PERFORM_CNS.SCORE.DESCRIPTION'] = X['PERFORM_CNS.SCORE.DESCRIPTION'].replace(('J-High Risk', 'K-High Risk'), (2, 2))\n\n    X['PERFORM_CNS.SCORE.DESCRIPTION'] = X['PERFORM_CNS.SCORE.DESCRIPTION'].replace(('H-Medium Risk', 'I-Medium Risk'), (3, 3))\n\n    X['PERFORM_CNS.SCORE.DESCRIPTION'] = X['PERFORM_CNS.SCORE.DESCRIPTION'].replace(('E-Low Risk', 'F-Low Risk', 'G-Low Risk'), (4, 4, 4))\n\n    X['PERFORM_CNS.SCORE.DESCRIPTION'] = X['PERFORM_CNS.SCORE.DESCRIPTION'].replace(('A-Very Low Risk', 'B-Very Low Risk',\n                                      'C-Very Low Risk', 'D-Very Low Risk'), (5, 5, 5, 5))\n    return X\n\ndef get_balance(df):\n    # down sampling negative instances(nondefault), keep all the positive instances\n    nondefault=df[df.loan_default==0].sample(n=df.loan_default.value_counts()[1], random_state=0)\n    default=df[df.loan_default==1]\n    df_balance= default.append(nondefault, ignore_index=True)\n    df_balance=df_balance.sample(n=len(df_balance))\n    return df_balance\n\n\ndef preprocess(df):\n    # transform birthDate to age\n    df['Date.of.Birth']=df['Date.of.Birth'].apply(lambda x: calculate_age(x))\n    df=df.rename(columns={'Date.of.Birth': 'Age'})\n\n    # one hot encoding Employment.Type\n    enc = OneHotEncoder(handle_unknown='ignore')\n    enc_df=pd.DataFrame(enc.fit_transform(df[['Employment.Type']]).toarray())\n    df=df.join(enc_df)\n    df.columns = df.columns.astype(str) \n    df=df.rename(columns={'0': 'Salaried',\n                       '1': 'Self_employed',\n                       '2': 'Unknown_employ'})\n    df=df.drop('Employment.Type',axis=1)\n\n    # \n    df['AVERAGE.ACCT.AGE']=df['AVERAGE.ACCT.AGE'].apply(lambda s: yrs_mon_to_month(s))\n    df['CREDIT.HISTORY.LENGTH']=df['CREDIT.HISTORY.LENGTH'].apply(lambda s: yrs_mon_to_month(s))\n\n    # transform DisbursalDate to month\n    df['DisbursalDate']=pd.to_datetime(df['DisbursalDate'],errors='coerce',dayfirst=True).dt.month\n    df=df.rename(columns={'DisbursalDate': 'DisbursalMonth'})\n\n    # encoding DisbursalMonth\n    df=pd.get_dummies(df, columns=[\"DisbursalMonth\"], prefix=[\"DisbursalMonth\"])\n    df['DisbursalMonth_8'] = df['DisbursalMonth_8'].astype(int)\n    df['DisbursalMonth_9'] = df['DisbursalMonth_8'].astype(int)\n    df['DisbursalMonth_10'] = df['DisbursalMonth_8'].astype(int)\n\n    # encoding description\n    df=encode_description(df)\n\n    #Â drop some columns with ID (will try encoding later)\n    id_col_to_drop=['UniqueID','Current_pincode_ID','supplier_id', 'Employee_code_ID']\n    df=df.drop(columns=id_col_to_drop)\n\n    # merge asset_cost and disbursed_amount\n    df['Downpayment']=df['asset_cost']-df['disbursed_amount']\n    df=df.drop(['asset_cost','disbursed_amount'],axis=1)\n\n    drop_max=['PRI.NO.OF.ACCTS','PRI.SANCTIONED.AMOUNT','PRI.DISBURSED.AMOUNT','DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS']\n    for d in drop_max:\n        df= df.drop(index=df[df[d]== max(df[d])].index[0])\n\n    drop_2max=['Downpayment','SEC.INSTAL.AMT']\n    for d in drop_2max:\n        df= df.drop(index=df[df[d]== max(df[d])].index[0])\n        df= df.drop(index=df[df[d]== max(df[d])].index[0])\n\n    # 'PRI.CURRENT.BALANCE', 'SEC.CURRENT.BALANCE' has negative values\n    #print('Taking logrithmic')\n    df['PRI.CURRENT.BALANCE']=df['PRI.CURRENT.BALANCE']-np.min(df['PRI.CURRENT.BALANCE'])\n    df['SEC.CURRENT.BALANCE']=df['SEC.CURRENT.BALANCE']-np.min(df['SEC.CURRENT.BALANCE'])\n\n\n    id_to_encode=['branch_id', 'manufacturer_id','State_ID']\n    for i in id_to_encode:\n        print('Encoding',i)\n        df= pd.get_dummies(df, columns=[i], prefix=['{}'.format(i)])\n\n    # merge PRI and SEC\n    df['Total.ACCTS'] = df[['PRI.NO.OF.ACCTS','SEC.NO.OF.ACCTS']].sum(axis=1)\n    df['Total.Active.ACCTS'] = df[['PRI.ACTIVE.ACCTS','SEC.ACTIVE.ACCTS']].sum(axis=1)\n    df['Total.Overdue.ACCTS'] = df[['PRI.OVERDUE.ACCTS','SEC.OVERDUE.ACCTS']].sum(axis=1)\n    df['Total.CurrentBalance'] = df[['PRI.CURRENT.BALANCE','SEC.CURRENT.BALANCE']].sum(axis=1)\n    df['Total.SanctionedAmount'] = df[['PRI.SANCTIONED.AMOUNT','SEC.SANCTIONED.AMOUNT']].sum(axis=1)\n    df['Total.DisbursedAmount'] = df[['PRI.DISBURSED.AMOUNT','SEC.DISBURSED.AMOUNT']].sum(axis=1)\n    df['Total.InstalAmount'] = df[['PRIMARY.INSTAL.AMT','SEC.INSTAL.AMT']].sum(axis=1)\n    # drop the above PRI and SEC\n    col_to_drop=['PRI.NO.OF.ACCTS','SEC.NO.OF.ACCTS','PRI.ACTIVE.ACCTS',\n    'SEC.ACTIVE.ACCTS','PRI.OVERDUE.ACCTS','SEC.OVERDUE.ACCTS',      'PRI.CURRENT.BALANCE','SEC.CURRENT.BALANCE',\n                    'PRI.SANCTIONED.AMOUNT','SEC.SANCTIONED.AMOUNT','PRI.DISBURSED.AMOUNT','SEC.DISBURSED.AMOUNT','PRIMARY.INSTAL.AMT','SEC.INSTAL.AMT']\n    df=df.drop(columns=col_to_drop)\n\n    to_log_cols=['ltv','Total.ACCTS','Total.Active.ACCTS','Total.Overdue.ACCTS','Total.CurrentBalance','Total.SanctionedAmount',\n    'Total.DisbursedAmount','Total.InstalAmount',\n       'NEW.ACCTS.IN.LAST.SIX.MONTHS', 'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS',\n       'AVERAGE.ACCT.AGE', 'CREDIT.HISTORY.LENGTH', 'NO.OF_INQUIRIES','Downpayment']\n    for c in to_log_cols:\n        df[c]=np.log1p(df[c])\n\n    # to_log_cols=['ltv','PRI.NO.OF.ACCTS', 'PRI.ACTIVE.ACCTS',\n    #    'PRI.OVERDUE.ACCTS' , 'PRI.SANCTIONED.AMOUNT',\n    #    'PRI.DISBURSED.AMOUNT', 'SEC.NO.OF.ACCTS', 'SEC.ACTIVE.ACCTS',\n    #    'SEC.OVERDUE.ACCTS', 'SEC.SANCTIONED.AMOUNT',\n    #    'SEC.DISBURSED.AMOUNT', 'PRIMARY.INSTAL.AMT', 'SEC.INSTAL.AMT',\n    #    'NEW.ACCTS.IN.LAST.SIX.MONTHS', 'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS',\n    #    'AVERAGE.ACCT.AGE', 'CREDIT.HISTORY.LENGTH', 'NO.OF_INQUIRIES','Downpayment','PRI.CURRENT.BALANCE', 'SEC.CURRENT.BALANCE']\n    # for c in to_log_cols:\n    #     df[c]=np.log1p(df[c])\n    #df=get_balance(df)\n    return df",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00002-bb944ceb-89cc-4aa0-a80c-b7391764750b",
    "deepnote_cell_type": "code"
   },
   "source": "train_raw=pd.read_csv('train_LTFS.csv')\ntrain=train_raw.copy()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00003-db5d5b0a-fcb4-4c04-90a9-5e2b301ffbb9",
    "deepnote_cell_type": "code"
   },
   "source": "train=preprocess(train)",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Encoding branch_id\nEncoding manufacturer_id\nEncoding State_ID\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00004-dd70262e-296b-485a-84d9-4fe9cbb63736",
    "deepnote_cell_type": "code"
   },
   "source": "train=get_balance(train)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00005-ffd809c6-e79f-4cac-9568-c0d6e8ba32a1",
    "deepnote_cell_type": "code"
   },
   "source": "train['loan_default'].value_counts()",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1    50609\n0    50609\nName: loan_default, dtype: int64"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00006-6e0f31dc-ef05-4890-90d1-096c904ff03a",
    "deepnote_cell_type": "code"
   },
   "source": "X = train.drop('loan_default',1) \ny = train.loan_default\nX_train, X_vali, y_train, y_vali = train_test_split(X, y, test_size=0.3,train_size=0.7,random_state=0)\n\n#modelRF = RandomForestClassifier(n_estimators=300,random_state=0,n_jobs=-1,verbose=1)\nmodelRF = RandomForestClassifier(n_estimators=300,random_state=0,n_jobs=-1,verbose=1)\nmodelRF.fit(X_train, y_train)\n\npredRF = modelRF.predict(X_vali)\n\nprint(\"Train Accuracy: \", modelRF.score(X_train, y_train))\nprint(\"Validation Accuracy: \", modelRF.score(X_vali, y_vali))\n\n#print(\"AUROC Score of Random Forest = \", roc_auc_score(Y_valid, Y_predRF))\n\n#save model\n# f = open('saved_RF_id_encoding_300tree2_smote_drop2','wb')\n# pickle.dump(modelRF,f)\n# f.close()\n# print('--------Model saved---------')\n\nconfusion = metrics.confusion_matrix(y_vali, predRF)\nprint('----confusion matrix----')\nprint(confusion)\nprint('Accuracy_Score:', metrics.accuracy_score(y_vali, predRF))\n# print('Sensitivity or Recall:', metrics.recall_score(y_vali, y_vali_pred))\nprint(classification_report(y_vali, predRF))",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.6s\n[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    7.9s\n[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:   12.9s finished\n[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.5s\n[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:    0.9s finished\n[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.3s\n[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    1.2s\n[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:    1.9s finished\n[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\nTrain Accuracy:  0.9997036075199006\n[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.5s\nValidation Accuracy:  0.5928670223276032\n----confusion matrix----\n[[9045 6165]\n [6198 8958]]\nAccuracy_Score: 0.5928670223276032\n              precision    recall  f1-score   support\n\n           0       0.59      0.59      0.59     15210\n           1       0.59      0.59      0.59     15156\n\n    accuracy                           0.59     30366\n   macro avg       0.59      0.59      0.59     30366\nweighted avg       0.59      0.59      0.59     30366\n\n[Parallel(n_jobs=8)]: Done 300 out of 300 | elapsed:    0.8s finished\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00007-62697b70-9f8d-421e-a195-e06eb81ba0e9",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=85463a1c-f246-4a97-953d-d1ccc73b61e9' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "752579dbebe7f4dfe7c1aa72eac13e23fc88be2cc1ea7ab14e1f8d69b2d97d12"
    }
   }
  },
  "deepnote_notebook_id": "8ab04558-882a-4abc-83d0-3ceaa4ee9f45",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}